# quepasa
API for RAG retrieval, managing documents, files, and related operations including Telegram integration.

This Python package is automatically generated by the [OpenAPI Generator](https://openapi-generator.tech) project:

- API version: 0.0.1
- Package version: 1.0.0
- Generator version: 7.8.0
- Build package: org.openapitools.codegen.languages.PythonClientCodegen

## Requirements.

Python 3.7+

## Installation & Usage
### pip install

If the python package is hosted on a repository, you can install directly using:

```sh
pip install quepasa
```
(you may need to run `pip` with root permission: `sudo pip install git+https://github.com/GIT_USER_ID/GIT_REPO_ID.git`)

Then import the package:
```python
import quepasa
```

## Getting Started

Please follow the [installation procedure](#installation--usage) and then run the following:

```python

import os
import time
from pprint import pprint

import quepasa
from quepasa.rest import ApiException

# The client must configure the authentication and authorization parameters
# in accordance with the API server security policy.
# Examples for each auth method are provided below, use the example that
# satisfies your auth use case.

# Configure Bearer authorization (Opaque): bearerAuth
configuration = quepasa.Configuration(
    access_token = os.environ["BEARER_TOKEN"]
)


# Enter a context with an instance of the API client
with quepasa.ApiClient(configuration) as api_client:
    # Create an instance of the API class
    client = quepasa.DefaultApi(api_client)

    domain = "default" # The name of a group of documents. Defaults to "default".
    doc_id = "llm"

    documents = [
        {
            # Required fields
            'id': doc_id, # string
            'url': "https://en.wikipedia.org/wiki/Large_language_model",

            'title': "Large language model",
            'language': "en", # two-char language code in lowercase
            'text': """
A large language model (LLM) is a computational model capable of language generation or other natural language processing tasks. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.

The largest and most capable LLMs, as of August 2024, are artificial neural networks built with a decoder-only transformer-based architecture, which enables efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks or can be guided by prompt engineering.
These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained on.

Some notable LLMs are OpenAI's GPT series of models (e.g., GPT-3.5, GPT-4 and GPT-4o; used in ChatGPT and Microsoft Copilot), Google's Gemini (the latter of which is currently used in the chatbot of the same name), Meta's LLaMA family of models, IBM's Granite models initially released with Watsonx, Anthropic's Claude models, and Mistral AI's models.
            """.strip(),
            # 'html': "", # or send text
            # 'markdown': "", # or send markdown

            # Optional fields:
            # - 'keywords': document keywords, string, by default empty
            # - 'created_at': "2024-05-20T07:26:06Z", # document creation datetime, by default datetime of first creation of this document via API
            # - 'updated_at': "2024-05-20T07:26:06Z", # document last update datetime, by default datetime of last update of this document via API
        },
    ]


    # Upsert document
    print("The response of client.replace_documents:")
    response = client.replace_documents(domain, documents)
    pprint(response)

    batch_id = response.data.batch_id


    # Wait until indexation is finished
    while batch_id != None:
        print("The response of client.get_batch_status:")
        response = client.get_batch_status(batch_id)
        pprint(response)

        time.sleep(10)
        if response.status == 'Batch state: done':
            break


    print("The response of client.retrieve_answer:")
    response = client.retrieve_answer({
        'question': "What is LLM?",
    })
    pprint(response)
    print(response.data.markdown)

```

### Upload file

```python

import os
import time
from pprint import pprint

import quepasa
from quepasa.rest import ApiException


# The client must configure the authentication and authorization parameters
# in accordance with the API server security policy.
# Examples for each auth method are provided below, use the example that
# satisfies your auth use case.

# Configure Bearer authorization (Opaque): bearerAuth
configuration = quepasa.Configuration(
    access_token = os.environ["BEARER_TOKEN"]
)


# Enter a context with an instance of the API client
with quepasa.ApiClient(configuration) as api_client:
    # Create an instance of the API class
    client = quepasa.DefaultApi(api_client)

    domain = "default" # The name of a group of documents. Defaults to "default".
    filename = "TimeTravel101ForBeginners.pdf"

    # Upload file
    print("The response of client.upsert_files:")
    response = client.upsert_files(domain, filename)
    pprint(response)

    batch_id = response.data.batch_id


    # Wait until indexation is finished
    while batch_id != None:
        print("The response of client.get_batch_status:")
        response = client.get_batch_status(batch_id)
        pprint(response)

        time.sleep(10)
        if response.status == 'Batch state: done':
            break


    print("The response of client.retrieve_answer:")
    response = client.retrieve_answer({
        'question': "Can I un-eat yesterday burrito?",
    })
    pprint(response)
    print(response.data.markdown)

```

## Documentation for API Endpoints

All URIs are relative to *https://api.quepasa.ai/api/v1*

Class | Method | HTTP request | Description
------------ | ------------- | ------------- | -------------
*DefaultApi* | [**upsert_files**](docs/DefaultApi.md#upsert_files) | **POST** /upload/data/files/{domain} | Upsert files
*DefaultApi* | [**upsert_documents**](docs/DefaultApi.md#upsert_documents) | **POST** /upload/data/documents/{domain} | Upsert documents
*DefaultApi* | [**replace_documents**](docs/DefaultApi.md#replace_documents) | **PUT** /upload/data/documents/{domain} | Replace documents
*DefaultApi* | [**get_batch_status**](docs/DefaultApi.md#get_batch_status) | **GET** /upload/data/batches/{id} | Get batch status
*DefaultApi* | [**get_document**](docs/DefaultApi.md#get_document) | **GET** /upload/data/documents/{domain}/{id} | Get document details
*DefaultApi* | [**list_documents**](docs/DefaultApi.md#list_documents) | **GET** /upload/data/documents/{domain} | List documents
*DefaultApi* | [**remove_document**](docs/DefaultApi.md#remove_document) | **DELETE** /upload/data/documents/{domain}/{id} | Remove document
*DefaultApi* | [**reset_documents**](docs/DefaultApi.md#reset_documents) | **DELETE** /upload/data/documents/{domain} | Reset documents
*DefaultApi* | [**retrieve_answer**](docs/DefaultApi.md#retrieve_answer) | **POST** /retrieve/answer | Retrieve answers or search data
*DefaultApi* | [**retrieve_chunks**](docs/DefaultApi.md#retrieve_chunks) | **POST** /retrieve/chunks | Retrieve answers or search data
*DefaultApi* | [**setup_telegram**](docs/DefaultApi.md#setup_telegram) | **PATCH** /upload/data/telegram | Setup Telegram integration


## Documentation For Models

 - [AnswerDetail](docs/AnswerDetail.md)
 - [AnswerDetailData](docs/AnswerDetailData.md)
 - [AnswerDetailDataLabeledLinksValue](docs/AnswerDetailDataLabeledLinksValue.md)
 - [AnswerDetailDataLinksValue](docs/AnswerDetailDataLinksValue.md)
 - [BatchStatus](docs/BatchStatus.md)
 - [BatchStatusData](docs/BatchStatusData.md)
 - [ChunksDetail](docs/ChunksDetail.md)
 - [ChunksDetailDataInner](docs/ChunksDetailDataInner.md)
 - [CreatedBatchStatus](docs/CreatedBatchStatus.md)
 - [CreatedBatchStatusData](docs/CreatedBatchStatusData.md)
 - [Document](docs/Document.md)
 - [DocumentDetail](docs/DocumentDetail.md)
 - [DocumentDetailData](docs/DocumentDetailData.md)
 - [DocumentDetailDataPagesInner](docs/DocumentDetailDataPagesInner.md)
 - [DocumentNotFound](docs/DocumentNotFound.md)
 - [DocumentPagesInner](docs/DocumentPagesInner.md)
 - [OperationFailedStatus](docs/OperationFailedStatus.md)
 - [RetrieveAnswerRequest](docs/RetrieveAnswerRequest.md)
 - [RetrieveAnswerRequestUserInfo](docs/RetrieveAnswerRequestUserInfo.md)
 - [SetupTelegramRequest](docs/SetupTelegramRequest.md)
 - [SetupTelegramRequestCommands](docs/SetupTelegramRequestCommands.md)
 - [SetupTelegramRequestCommandsAsk](docs/SetupTelegramRequestCommandsAsk.md)
 - [SetupTelegramRequestCommandsStart](docs/SetupTelegramRequestCommandsStart.md)
 - [TelegramStatus](docs/TelegramStatus.md)


<a id="documentation-for-authorization"></a>
## Documentation For Authorization


Authentication schemes defined for the API:
<a id="bearerAuth"></a>
### bearerAuth

- **Type**: Bearer authentication (Opaque)


## Development
### Setuptools

Install via [Setuptools](http://pypi.python.org/pypi/setuptools).

```sh
python setup.py install --user
```
(or `sudo python setup.py install` to install the package for all users)

Then import the package:
```python
import quepasa
```

### Tests

Execute `pytest` to run the tests.


## Author
QuePasa.ai
